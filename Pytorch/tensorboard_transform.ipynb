{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/5.6 MB 3.3 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.5/5.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 0.9/5.6 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.5/5.6 MB 8.4 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.0/5.6 MB 9.1 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 2.5/5.6 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 9.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 3.6/5.6 MB 10.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.1/5.6 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 4.6/5.6 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.2/5.6 MB 10.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 9.6 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 0.0/126.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.5/126.5 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from tensorboard) (67.8.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from tensorboard) (0.38.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from tensorboard) (1.24.3)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.23.3-cp39-cp39-win_amd64.whl (422 kB)\n",
      "     ---------------------------------------- 0.0/422.5 kB ? eta -:--:--\n",
      "     ------------------------------------  419.8/422.5 kB 13.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- 422.5/422.5 kB 13.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from tensorboard) (2.28.1)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.56.0-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.5/4.2 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.1/4.2 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.6/4.2 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 2.2/4.2 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 2.7/4.2 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.3/4.2 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 3.9/4.2 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 0.0/93.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 93.9/93.9 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.20.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.5/181.5 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "     ---------------------------------------- 0.0/242.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 242.5/242.5 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.3/181.3 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.13)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from markdown>=2.6.8->tensorboard) (6.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tsx10\\anaconda3\\envs\\computer_vision\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.15.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 0.0/83.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.9/83.9 kB ? eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, pyasn1, protobuf, oauthlib, grpcio, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.4.0 cachetools-5.3.1 google-auth-2.20.0 google-auth-oauthlib-1.0.0 grpcio-1.56.0 markdown-3.4.3 oauthlib-3.2.2 protobuf-4.23.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 werkzeug-2.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Graph using tensorboard\n",
    "add_scalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "# writer.add_image()\n",
    "# writer.add_scalar()\n",
    "for i in range(100):\n",
    "    writer.add_scalar(\"y=2x\", scalar_value=2*i, global_step=i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show images using tensorboard\n",
    "add_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 80, 151, 233],\n",
       "        [ 80, 151, 233],\n",
       "        [ 80, 151, 233],\n",
       "        ...,\n",
       "        [ 81, 152, 234],\n",
       "        [ 79, 150, 232],\n",
       "        [ 76, 147, 229]],\n",
       "\n",
       "       [[ 81, 152, 234],\n",
       "        [ 81, 152, 234],\n",
       "        [ 81, 152, 234],\n",
       "        ...,\n",
       "        [ 81, 152, 234],\n",
       "        [ 79, 150, 232],\n",
       "        [ 76, 147, 229]],\n",
       "\n",
       "       [[ 82, 153, 235],\n",
       "        [ 82, 153, 235],\n",
       "        [ 82, 153, 235],\n",
       "        ...,\n",
       "        [ 80, 151, 233],\n",
       "        [ 79, 150, 232],\n",
       "        [ 77, 148, 230]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 87, 160, 237],\n",
       "        [ 87, 160, 237],\n",
       "        [ 86, 159, 236],\n",
       "        ...,\n",
       "        [ 44,  92, 141],\n",
       "        [ 95, 158, 235],\n",
       "        [ 90, 157, 228]],\n",
       "\n",
       "       [[ 87, 160, 237],\n",
       "        [ 87, 160, 237],\n",
       "        [ 86, 159, 236],\n",
       "        ...,\n",
       "        [ 84, 147, 226],\n",
       "        [ 90, 160, 255],\n",
       "        [ 84, 152, 233]],\n",
       "\n",
       "       [[ 87, 160, 237],\n",
       "        [ 87, 160, 237],\n",
       "        [ 86, 159, 236],\n",
       "        ...,\n",
       "        [ 79, 160, 242],\n",
       "        [ 78, 159, 250],\n",
       "        [ 84, 161, 233]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = r\"C:\\Users\\tsx10\\PythonProjectsJupyter\\Python_Vertiefen\\Pytorch\\Dataset\\Data\\train\\ants_image\\0013035.jpg\"\n",
    "image_array = np.array(Image.open(image_path))\n",
    "image_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataformat define the dataform like PIL and Opencv have different input channals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image(tag=\"test\", img_tensor=image_array, global_step=1, dataformats=\"HWC\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image preporcessing using transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforms.ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3137, 0.3137, 0.3137,  ..., 0.3176, 0.3098, 0.2980],\n",
       "         [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3098, 0.2980],\n",
       "         [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3098, 0.3020],\n",
       "         ...,\n",
       "         [0.3412, 0.3412, 0.3373,  ..., 0.1725, 0.3725, 0.3529],\n",
       "         [0.3412, 0.3412, 0.3373,  ..., 0.3294, 0.3529, 0.3294],\n",
       "         [0.3412, 0.3412, 0.3373,  ..., 0.3098, 0.3059, 0.3294]],\n",
       "\n",
       "        [[0.5922, 0.5922, 0.5922,  ..., 0.5961, 0.5882, 0.5765],\n",
       "         [0.5961, 0.5961, 0.5961,  ..., 0.5961, 0.5882, 0.5765],\n",
       "         [0.6000, 0.6000, 0.6000,  ..., 0.5922, 0.5882, 0.5804],\n",
       "         ...,\n",
       "         [0.6275, 0.6275, 0.6235,  ..., 0.3608, 0.6196, 0.6157],\n",
       "         [0.6275, 0.6275, 0.6235,  ..., 0.5765, 0.6275, 0.5961],\n",
       "         [0.6275, 0.6275, 0.6235,  ..., 0.6275, 0.6235, 0.6314]],\n",
       "\n",
       "        [[0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9098, 0.8980],\n",
       "         [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9098, 0.8980],\n",
       "         [0.9216, 0.9216, 0.9216,  ..., 0.9137, 0.9098, 0.9020],\n",
       "         ...,\n",
       "         [0.9294, 0.9294, 0.9255,  ..., 0.5529, 0.9216, 0.8941],\n",
       "         [0.9294, 0.9294, 0.9255,  ..., 0.8863, 1.0000, 0.9137],\n",
       "         [0.9294, 0.9294, 0.9255,  ..., 0.9490, 0.9804, 0.9137]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_path = r\"C:\\Users\\tsx10\\PythonProjectsJupyter\\Python_Vertiefen\\Pytorch\\Dataset\\Data\\train\\ants_image\\0013035.jpg\"\n",
    "img = Image.open(image_path)\n",
    "tensor_trans = transforms.ToTensor() # return ToTensor class \n",
    "tensor_img = tensor_trans(img) # Convert a PIL Image or ndarray to tensor and scale the values accordingly\n",
    "tensor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why Tensor datatype? we have more attribute for trainning and benifit for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image(tag=\"test_\", img_tensor=tensor_img, global_step=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different input or output data type\n",
    "- Tensor\n",
    "- Opencv\n",
    "- PIL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3725, -0.3725, -0.3725,  ..., -0.3647, -0.3804, -0.4039],\n",
       "         [-0.3647, -0.3647, -0.3647,  ..., -0.3647, -0.3804, -0.4039],\n",
       "         [-0.3569, -0.3569, -0.3569,  ..., -0.3725, -0.3804, -0.3961],\n",
       "         ...,\n",
       "         [-0.3176, -0.3176, -0.3255,  ..., -0.6549, -0.2549, -0.2941],\n",
       "         [-0.3176, -0.3176, -0.3255,  ..., -0.3412, -0.2941, -0.3412],\n",
       "         [-0.3176, -0.3176, -0.3255,  ..., -0.3804, -0.3882, -0.3412]],\n",
       "\n",
       "        [[ 0.1843,  0.1843,  0.1843,  ...,  0.1922,  0.1765,  0.1529],\n",
       "         [ 0.1922,  0.1922,  0.1922,  ...,  0.1922,  0.1765,  0.1529],\n",
       "         [ 0.2000,  0.2000,  0.2000,  ...,  0.1843,  0.1765,  0.1608],\n",
       "         ...,\n",
       "         [ 0.2549,  0.2549,  0.2471,  ..., -0.2784,  0.2392,  0.2314],\n",
       "         [ 0.2549,  0.2549,  0.2471,  ...,  0.1529,  0.2549,  0.1922],\n",
       "         [ 0.2549,  0.2549,  0.2471,  ...,  0.2549,  0.2471,  0.2627]],\n",
       "\n",
       "        [[ 0.8275,  0.8275,  0.8275,  ...,  0.8353,  0.8196,  0.7961],\n",
       "         [ 0.8353,  0.8353,  0.8353,  ...,  0.8353,  0.8196,  0.7961],\n",
       "         [ 0.8431,  0.8431,  0.8431,  ...,  0.8275,  0.8196,  0.8039],\n",
       "         ...,\n",
       "         [ 0.8588,  0.8588,  0.8510,  ...,  0.1059,  0.8431,  0.7882],\n",
       "         [ 0.8588,  0.8588,  0.8510,  ...,  0.7725,  1.0000,  0.8275],\n",
       "         [ 0.8588,  0.8588,  0.8510,  ...,  0.8980,  0.9608,  0.8275]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # input mean and standard\n",
    "img_norm = trans_norm(tensor_img) # output[channel] = (input[channel] - mean[channel]) / std[channel] \n",
    "img_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input is PIL image\n",
    "\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms_resize = transforms.Resize((512, 512))\n",
    "transforms_resize.size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conpose() more step preporcessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms_compose = transforms.Compose([transforms.Resize(512), transforms.ToTensor()]) # resize first and then to tensor\n",
    "transforms_compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3137, 0.3137, 0.3137,  ..., 0.3176, 0.3098, 0.2980],\n",
       "         [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3098, 0.2980],\n",
       "         [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3098, 0.3020],\n",
       "         ...,\n",
       "         [0.3412, 0.3412, 0.3373,  ..., 0.1725, 0.3725, 0.3529],\n",
       "         [0.3412, 0.3412, 0.3373,  ..., 0.3294, 0.3529, 0.3294],\n",
       "         [0.3412, 0.3412, 0.3373,  ..., 0.3098, 0.3059, 0.3294]],\n",
       "\n",
       "        [[0.5922, 0.5922, 0.5922,  ..., 0.5961, 0.5882, 0.5765],\n",
       "         [0.5961, 0.5961, 0.5961,  ..., 0.5961, 0.5882, 0.5765],\n",
       "         [0.6000, 0.6000, 0.6000,  ..., 0.5922, 0.5882, 0.5804],\n",
       "         ...,\n",
       "         [0.6275, 0.6275, 0.6235,  ..., 0.3608, 0.6196, 0.6157],\n",
       "         [0.6275, 0.6275, 0.6235,  ..., 0.5765, 0.6275, 0.5961],\n",
       "         [0.6275, 0.6275, 0.6235,  ..., 0.6275, 0.6235, 0.6314]],\n",
       "\n",
       "        [[0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9098, 0.8980],\n",
       "         [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9098, 0.8980],\n",
       "         [0.9216, 0.9216, 0.9216,  ..., 0.9137, 0.9098, 0.9020],\n",
       "         ...,\n",
       "         [0.9294, 0.9294, 0.9255,  ..., 0.5529, 0.9216, 0.8941],\n",
       "         [0.9294, 0.9294, 0.9255,  ..., 0.8863, 1.0000, 0.9137],\n",
       "         [0.9294, 0.9294, 0.9255,  ..., 0.9490, 0.9804, 0.9137]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms_compose(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomcrop() ... see documentation ctrl click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
